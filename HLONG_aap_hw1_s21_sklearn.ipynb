{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda9e8e-c33d-4480-9b68-3cb4a15b0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the raw data\n",
    "\n",
    "tax_df = pd.read_csv(\"./data/raw/taxinfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90dfbe-dd8f-4e44-ae8d-16b5cd67b2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Review structure of data frame\n",
    "\n",
    "tax_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883217bd-fe36-4c1f-b2c2-5db93d3eb25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA - sweetviz\n",
    "\n",
    "import sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f89353-a6c4-4a2c-9242-eeef54d52d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = sweetviz.analyze(tax_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7dbb9d-77b6-4dac-9452-c704dcd7c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.show_html(\"output/sweetviz_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408890e-8fa5-4c9c-809c-4d351ecb5aec",
   "metadata": {},
   "source": [
    "<b>After reviewing the sweetviz html output, here are some things I noticed about the data:<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1ae59-98f4-4d89-9116-810c0c1cfe29",
   "metadata": {},
   "source": [
    "-  Median household income is $154K\n",
    "-  There is an association between \"College Grads\" and \"Household Debt Level.\" This would make sense because a lot of people have student loans to pay off once they graduate from college and/or maybe mom and dad take out a loan to help pay for their kids college education. It looks like 85% of respondents have one or more college graduates living in the house.\n",
    "-  There is an association between \"Cars\" and \"Average Age of People in Household.\" The avearge age is 60.6 with a minimum age of 18 so it can probably be assumed that all respondents have their license. Only 17% of respondents said there were zero cars at the household and all other responses collected noted 1-5 cars at the houeshold (almost 50% of respondents have 3-5 cars).\n",
    "-  The responses are split pretty evenly amongst political party - Independent, Democrat, and Republican were all pretty much at 33% so it will be interesting to see how the regression will use other factors to predict political party since one variable is not more dominant than the others.\n",
    "-  It is interesting that 50% of people are not submitting their taxes to the IRS in each year...not sure how that happens lol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175fb5f-1d01-48be-b5fb-52f33edff1c9",
   "metadata": {},
   "source": [
    "<b>Now I am going to see what is currently numeric and categorical variable:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67870a22-5892-4831-9c25-019afc92f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to creating my regression model, I'll split the tax_df in to two (I assume this is like doing a \"test\" and \"train\" data frame...maybe).\n",
    "# I also do not want to transform my y-variable (PoliticalParty) so I'll only be working off of the \"X\" data frame\n",
    "\n",
    "X = tax_df.iloc[:, 0:9]\n",
    "y = tax_df.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63299a6-135e-40bd-b0d5-4fc206249c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c407204-6cbd-43de-bf84-67042a89fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing numeric and categorical columns in data frame X to help with data processing\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "all_cols = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801febe-4395-4e8b-9c0f-02ed753fb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb09705-3a28-4433-8262-b5b1f0ee955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f844b-bbcf-44c0-835b-97ffcfb3dc88",
   "metadata": {},
   "source": [
    "<b> I think \"Married\" and \"Filed\" years (since it is a binary response) should be categorical. \"Married\" is not a binary response but it appears to be categorical; maybe 0 = Single, 1 = Married, 2 = Divorced, etc.<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2dffc-0ec7-4127-8aeb-3c87f171a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change some variables in data frame X to categorical\n",
    "\n",
    "X = X.astype({\"Married\":'object', \"Filed_2015\":'object', \"Filed_2016\":'object', \"Filed_2017\":'object'})\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c15c876-a0b8-40ef-9cc3-52a13ad6df40",
   "metadata": {},
   "source": [
    "<b>I have have my data frame(s) where I want them so now I can begin with regression modeling...let's see how this goes :)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27daba0b-5ad9-4e06-89b5-491f0ea38b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary packages/transformers\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108c101-b7fe-4b5a-897c-06aeb7ca740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "\n",
    "# Create transformer objects\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine transformers into a preprocessor step\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Classifier model with C=1\n",
    "clf_model = LogisticRegression(penalty='l2', C=1, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b627ae6-4943-4c5c-ba59-65ef672e7b28",
   "metadata": {},
   "source": [
    "<b>Let's see a picture of my pipeline:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fec2d4-32bf-4171-bed1-a70fcce7488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bdbe43-f78c-4ec5-9e40-8309e28bb6a7",
   "metadata": {},
   "source": [
    "<b>Time to partition the data for further model fitting and testing<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c98abe-9658-4cf9-8cf3-30735a335655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the partitioning in the HW instructions\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "# Fit model on new training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659c011-acf3-49c5-a6d4-fb7f5e26d35d",
   "metadata": {},
   "source": [
    "**Well that score sucks...lets create a new model and adjust the value of C = 0.01 and put more weight on the regularization penalty term.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95199262-1cef-4fb3-ab63-87513222a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model with C = 0.01\n",
    "clf_model_C01 = LogisticRegression(penalty='l2', C=0.01, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_C01 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_model_C01)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_C01.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf_C01.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf_C01.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b7449e-977e-4c75-b137-8877262b1a72",
   "metadata": {},
   "source": [
    "**Not much better. I'm going to try a few different models with varying values of C to determine which one is best.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7f382-87fa-4b51-a7e1-3bf8d79f7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model with C = 0.05\n",
    "clf_model_C05 = LogisticRegression(penalty='l2', C=0.05, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_C05 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_model_C05)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_C05.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf_C05.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf_C05.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f45e18-5564-4280-9dc6-9d37a9f338c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model with C = 5\n",
    "clf_model_C50 = LogisticRegression(penalty='l2', C=5, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_C50 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_model_C50)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_C50.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf_C50.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf_C50.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e988d4c-72cb-4faa-9d4b-9786fb085395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model with C = 5\n",
    "clf_model_C5 = LogisticRegression(penalty='l2', C=5, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_C5 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_model_C5)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_C5.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf_C5.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf_C5.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2d185-8227-48bd-aafe-c9327398ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model with C = 10\n",
    "clf_model_C10 = LogisticRegression(penalty='l2', C=10, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_C10 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_model_C10)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_C10.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf_C10.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf_C10.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0a4a6-7c73-4f49-85af-ed7c9e799a0f",
   "metadata": {},
   "source": [
    "**So as I am running all these models with different C values, I'm realizing that the larger my C value, the worse (or no change) my scores get. I am going to try running smaller values of C.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef8e51-76da-4a89-8794-5baaf6834217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model with C = 0.001\n",
    "clf_model_C001 = LogisticRegression(penalty='l2', C=0.001, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_C001 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_model_C001)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_C001.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf_C001.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf_C001.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa482a3-8319-446a-8f40-a019d0f5e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model with C = 0.0005\n",
    "clf_model_C0005 = LogisticRegression(penalty='l2', C=0.0005, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_C0005 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_model_C0005)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_C0005.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf_C0005.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf_C0005.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911cdd16-72e0-4404-a2c1-7acc14b9f264",
   "metadata": {},
   "source": [
    "**It looks like my best score based on the C values I've used to this point is when C = 0.001 (traning = 0.405, test = 0.308). I am going to roll with this one to create my  final prediction, random forest and confusion matrix. The score is not great, I would have rather it had been closer to 80% but based on what I am gathering, a larger C value the lower the score so the model needs higher regularization to improve results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d588272-9efd-4c3e-8400-e47ca07af3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final logistic regression classifier model\n",
    "clf_LR_model_final = LogisticRegression(penalty='l2', C=0.001, solver='saga', max_iter=500)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_LR_final = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_LR_model_final)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_LR_final.fit(X_train, y_train)\n",
    "print(\"Training score: %.3f\" % clf_LR_final.score(X_train, y_train))\n",
    "\n",
    "# Make predictions on the test data\n",
    "clf_LR_final_predictions = clf_LR_final.predict(X_test)\n",
    "print(clf_LR_final_predictions[:10])  # Print out a few predictions just to see what they look like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631a95d-3449-4a82-9303-eff92e13b82a",
   "metadata": {},
   "source": [
    "**Overall it looks like we only have a 40% chance of accruately guessing someones Political Party based on the variables provided in the data set and high regularization. Let's create a random forest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071170df-0246-491e-9e2d-e4830ce4188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Append random forest classifier to preprocessing pipeline.\n",
    "clf_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(oob_score=True, random_state=0))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training score: {clf_rf.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test score: {clf_rf.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b27be4-6e6c-40a3-87b1-90d68a8dcce1",
   "metadata": {},
   "source": [
    "**Wow, higher accuracy on the training data but the test data is still in line with the results from the regression modeling; we may be overfitting the data. Let's see what a confusion matrix looks like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8c87a-79ae-41e8-88e8-06c2c89b67ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Creating confusing matrix on training data\n",
    "\n",
    "titles_options = [(\"Confusion matrix for train, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix for train\", 'true')]\n",
    "\n",
    "class_names = clf_rf['classifier'].classes_\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf_rf, X_train, y_train,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3106c8-814a-4546-a1b0-86438246556b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating confusing matrix on test data\n",
    "\n",
    "titles_options = [(\"Confusion matrix for test, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix for test\", 'true')]\n",
    "\n",
    "class_names = clf_rf['classifier'].classes_\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf_rf, X_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47924d-8e10-493e-aea2-0cc822157229",
   "metadata": {},
   "source": [
    "**I think one of the issues is how evenly spread the data is; there is not one Poltical Party more dominant than the others. It looks like Democrat is the \"easiest\" to predict whereas Independent is the most difficult to predict. Let's do a final random forest classifier model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2e50b-f6ed-4182-a5e0-4f43f1831aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final random forest classifier model\n",
    "clf_RF_model_final = RandomForestClassifier(oob_score=True, random_state=0)\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "clf_RF_final = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', clf_RF_model_final)])\n",
    "\n",
    "# Fit model on training data \n",
    "clf_RF_final.fit(X_train, y_train)\n",
    "print(\"Training score: %.3f\" % clf_RF_final.score(X_train, y_train))\n",
    "\n",
    "# Make predictions on the test data\n",
    "clf_RF_final_predictions = clf_RF_final.predict(X_test)\n",
    "print(clf_RF_final_predictions[:10])  # Print out a few predictions just to see what they look like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716c26b-95ad-4036-a4b1-754645f94e47",
   "metadata": {},
   "source": [
    "**No changes here...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8e033-20ff-4c0a-a060-ba1781615a26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>In summary, it looks like it is hard to predict Political Party. I think it is a combination of things such as the training data set or how evenly spead the Political Party response was amongst the three options. I ended up creating a \"Play\" variable to try different values of C and I could not for the life of me improve my score; it either stayed at 40% or went below. I tried to replace LogisticRegression with LogisitcRegressionCV but I kept getting error messages about things may not being defined (it is 11PM on a Sunday as a type this, so maybe I'll try again another day). I thinkt the random forest overfit my model because the training data accuracy was 100%...so...theres that.<b>\n",
    "</div>\n",
    "    \n",
    "Update 5/18 - Submitting as is :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071296d9-4719-4764-bd38-a07863bf2561",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>***********************************************************************************HW INSTRUCTIONS / NOTES BEYOND THIS POINT**********************************************************************************<b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc17827",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HW1 - Classification models in sklearn\n",
    "\n",
    "You'll be building a few classifier models and using some of the tech tools we learned about in Modules 1 and 2. \n",
    "\n",
    "## The Data\n",
    "\n",
    "The data is a relatively small and simple dataset of taxpayer data. I got it from:\n",
    "\n",
    "https://www.kaggle.com/dmaillie/sample-us-taxpayer-dataset\n",
    "\n",
    "As you'll see if you visit that page, this dataset was used in a series of YouTube tutorials on using R to build random forest models. \n",
    "\n",
    "I read it into a pandas dataframe and used `info()` to get:\n",
    "\n",
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 1004 entries, 0 to 1003\n",
    "Data columns (total 10 columns):\n",
    " #   Column          Non-Null Count  Dtype \n",
    "---  ------          --------------  ----- \n",
    " 0   HHI             1004 non-null   int64 \n",
    " 1   HHDL            1004 non-null   int64 \n",
    " 2   Married         1004 non-null   int64 \n",
    " 3   CollegGrads     1004 non-null   int64 \n",
    " 4   AHHAge          1004 non-null   int64 \n",
    " 5   Cars            1004 non-null   int64 \n",
    " 6   Filed_2017      1004 non-null   int64 \n",
    " 7   Filed_2016      1004 non-null   int64 \n",
    " 8   Filed_2015      1004 non-null   int64 \n",
    " 9   PoliticalParty  1004 non-null   object\n",
    "dtypes: int64(9), object(1)\n",
    "memory usage: 78.6+ KB\n",
    "```\n",
    "\n",
    "Some information about the fields:\n",
    "\n",
    "* `HHI` - household income\n",
    "* `HHDL` - household debt level\n",
    "* `Married` - categorical with a few levels\n",
    "* `CollegGrads` - number of college grads in the household\n",
    "* `AHHAge` - average age of people in the household\n",
    "* `Cars` - number of cars in the household\n",
    "* `Filed_2017` - 1 means they filed a tax return with the IRS for 2017\n",
    "* `Filed_2016` - 1 means they filed a tax return with the IRS for 2016\n",
    "* `Filed_2015` - 1 means they filed a tax return with the IRS for 2015\n",
    "* `PoliticalParty` - categorical with 3 levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabbbf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Problem\n",
    "\n",
    "Our overall goal is to build classifier models to predict `PoliticalParty` using the the other variables. You must use sklearn Pipelines that contain your preprocessing steps and your model estimation step.\n",
    "\n",
    "You can do your work in a Jupyter Notebook(s) or in a Python script(s) (i.e. a ``.py`` file) or both. It's up to you.\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Start by creating a new project folder structure with the cookiecutter-datascience-simple template that I covered in Module 1. Put the data file into its appropriate folder and put this notebook in the main project folder. Any additional notebooks and/or Python files you end up creating should go in the main project folder.\n",
    "\n",
    "**HL 5/12/2021 - DONE**\n",
    "\n",
    "### Task 2\n",
    "\n",
    "Put your new project folder under version control using git. You should **NOT** track the data file. You must track any notebooks, Python scripts or additional text files you end up creating.\n",
    "\n",
    "**HL 5/12/2021 - DONE, just need to do another commit when finished**\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Build at least one logistic regression model (with regularization) and one random forest model to predict `PoliticalParty`. Yes, this is very similar to what we did for the Pump it Up project in Module 2. Some detailed requirements and additional information:\n",
    "\n",
    "* I suggest you start by reading the csv file into a pandas dataframe. My dataframe is called ``tax_df``.\n",
    "* Then start with some basic EDA. You can certainly use automated tools such as pandas-profiling or SweetViz as I showed in the class notes. Remember, when you run either of those, you **must** have your notebook open in the classic Jupyter Notebook interface (and **NOT** in Jupyter Lab). Once you've created the EDA reports you can close your notebook and reopen in Jupyter Lab if you wish. As we've seen, the reports get created as HTML documents. These should go in your output folder within your project.\n",
    "* Since we are using regularization, all of the numeric variables should be rescaled using the `StandardScaler` - be careful, just because a variable has a numeric datatype in the pandas dataframe, it does not mean that it's necessarily a numeric variable in the context of the classification models. Think about each column and look at your EDA reports and decide whether or not it's truly numeric or needs to be treated as categorical data in the models.\n",
    "* For any variables that you decide should be treated as categorical in your models, use the `OneHotEncoder` on them in the preprocessing stage.\n",
    "* Even though our target variable, `PoliticalParty`, is categorical, you do **NOT** need to do any preprocessing on it. As I mentioned in our class notes, scikit-learn will automatically detect that and will do any encoding needed on its own (it uses the `LabelEncoder`).\n",
    "* I broke up the ``tax_df`` into two separate dataframes that I called ``X`` and ``y``, to use in the models. Here's my code for that:\n",
    "\n",
    "```\n",
    "X = tax_df.iloc[:, 0:9]\n",
    "y = tax_df.iloc[:, 9]\n",
    "```\n",
    "\n",
    "* Please use the following code for your data partitioning so that we all end up with the same training and test split:\n",
    "\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "```\n",
    "\n",
    "* For each model you fit, you should compute its ``score`` and create a confusion matrix on both train and test data. I did all of this repeatedly in the class notes.\n",
    "* For each model (the logistic regression model and the random forest) you should make some summary comments about how well the model fits and predicts and if there is evidence of overfitting. \n",
    "\n",
    "**IMPORTANT** You always should put summary comments in a markdown cell. Do **NOT** write them as comments in a code cell. The whole point of Jupyter notebooks is to be able to mix markdown cells with code cells. If you choose to do all of your Python work in a ``.py`` file(s), then simple create a Jupyter notebook in which you include your summary comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026c076",
   "metadata": {},
   "source": [
    "## Optional Hacker Extra tasks\n",
    "I always like to include some extra credit tasks for those who want to push themselves a little further. For this problem, consider doing one or more of the following:\n",
    "\n",
    "* Try out the Histogram based Gradient Boosting Classifier shown in the optional materials at the end of Module 2. Compare its performance to logistic regression and the random forest.\n",
    "* Create a second set of models in which you treat ``Filed_2017`` as a binary target variable and use ``PoliticalParty`` as a categorical feature variable. Is it any easier to predict ``Filed_2017`` than it was to predict ``PoliticalParty``?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32e527",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "You should simply compress your entire project folder as either a zip file or a tar.gz file (do **NOT** ever use WinRAR to create rar files in this class). Note that when you do this, your \"hidden\" ``.git`` folder will get included. So, I'll be able to tell that you put the project under version control and I'll be able to look at your project folder structure. Before compressing the project folder to submit it:\n",
    "\n",
    "* make sure all of your notebooks and .py files are in the main project folder and have good filenames,\n",
    "* make sure you've committed all of your changes (git),\n",
    "* upload your compressed folder in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0ad2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
